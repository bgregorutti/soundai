{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Exploring the biases in embeddings: Word2Vec, BERT and GPT2\n",
        "\n",
        "The goal of this workshop is to explore the concepts of bias in NLP algorithms such as Word2Vec, BERT of GPT2 and the associated models.\n",
        "\n",
        "References:\n",
        "\n",
        "*   [Bolukbasi et al 2016](https://arxiv.org/abs/1607.06520)\n",
        "*   [Ellis et al 2022](https://cs.carleton.edu/cs_comps/2223/replication/final-results-4/filez/Debiasewe_Final_Paper.pdf)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ROSGeEvLYzYh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukKdEN81pGZ2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import gensim.downloader as api\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from transformers import GPT2Model, GPT2Tokenizer, AutoModel, AutoTokenizer, BertModel, BertTokenizer\n",
        "from torch import cosine_similarity, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some useful functions"
      ],
      "metadata": {
        "id": "7ushUUti_IZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG-B8ugwpGaF"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_json(url):\n",
        "    resp = requests.get(url)\n",
        "    return json.loads(resp.text)\n",
        "\n",
        "def get_embedding(target_word, tokenizer, model):\n",
        "    \"\"\"\n",
        "    Get the embedding vector of models from HuggingFace (transformers package)\n",
        "    \"\"\"\n",
        "    input_ids = tokenizer.encode(target_word, add_special_tokens=True)\n",
        "    outputs = model(tensor([input_ids]))[0]\n",
        "    return outputs.mean(1)\n",
        "\n",
        "def analogy_w2v(word_embedding, positive, negative, topn=5):\n",
        "    \"\"\"\n",
        "    Compute analogies, i.e. operations on the embedding vectors and similarities with a corpus\n",
        "    For gensim models\n",
        "    \"\"\"\n",
        "    similars = word_embedding.most_similar(positive=positive, negative=negative, topn=topn)\n",
        "    for item in similars:\n",
        "        print(item)\n",
        "\n",
        "def analogy(model, tokenizer, positive, negative, corpus, topn=5):\n",
        "    \"\"\"\n",
        "    Compute analogies, i.e. operations on the embedding vectors and similarities with a corpus\n",
        "    For HugingFace models\n",
        "    \"\"\"\n",
        "    assert len(positive) == 2\n",
        "    assert len(negative) == 1\n",
        "\n",
        "    # Get the words\n",
        "    word_1, word_2 = positive\n",
        "    word_3 = negative[0]\n",
        "\n",
        "    # Compute the embedding of word_1 - word_3 + word_2, i.e. the target\n",
        "    vector = get_embedding(target_word=word_1, model=model, tokenizer=tokenizer)\n",
        "    vector += get_embedding(target_word=word_2, model=model, tokenizer=tokenizer)\n",
        "    vector -= get_embedding(target_word=word_3, model=model, tokenizer=tokenizer)\n",
        "\n",
        "    # Loop over all of the words in a corpus, compute the embedding and compare with the target\n",
        "    print(f\"{word_1} - {word_2} + {word_3} = ?\")\n",
        "    res = []\n",
        "    for word in corpus:\n",
        "        if word.isalnum():\n",
        "            emb = get_embedding(word, tokenizer=tokenizer, model=model)\n",
        "            similarity = cosine_similarity(vector, emb).mean()\n",
        "            res.append([word, similarity.numpy(force=True)])\n",
        "\n",
        "    # Get the topn most similar words\n",
        "    res = np.array(res)\n",
        "    indexes = np.argsort(res[:, 1])[::-1]\n",
        "    res = res[indexes[:topn]]\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias in Word2Vec models"
      ],
      "metadata": {
        "id": "6r3RNPoM2dGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore `gensim` package\n",
        "\n",
        "The package gensim is dedicated to the computation of word embedding for models trained with Word2Vec NN architecture\n",
        "\n",
        "https://radimrehurek.com/gensim/"
      ],
      "metadata": {
        "id": "42iIZ7JZx3qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints the datasets available in gensim\n",
        "print(\"Datasets:\\n\")\n",
        "for item in api.info().get(\"corpora\"):\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "CB82skP6x3a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all available pre-trained models\n",
        "print(\"Pre-trained models:\\n\")\n",
        "for m in api.info().get(\"models\"):\n",
        "    print(m)"
      ],
      "metadata": {
        "id": "rVr9whsmyNCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints the metadata of well-known pre-trained models\n",
        "\n",
        "# Model 1: word2vec-google-news-300\n",
        "print(json.dumps(api.info().get(\"models\").get(\"word2vec-google-news-300\"), indent=4))\n",
        "\n",
        "# Model 2: word2vec-google-news-300\n",
        "print(json.dumps(api.info().get(\"models\").get(\"glove-twitter-25\"), indent=4))\n"
      ],
      "metadata": {
        "id": "tuZLTCJQ2ASI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw8dLtAApGaA"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained models (the loading may be long...)\n",
        "\n",
        "# Load glove-twitter-25\n",
        "glove_word_embedding = api.load(\"glove-twitter-25\")\n",
        "\n",
        "# Load word2vec-google-news-300\n",
        "news_word_embedding = api.load(\"word2vec-google-news-300\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the embedding vectors\n",
        "glove_word_embedding.vectors.shape"
      ],
      "metadata": {
        "id": "8g8_hD-t4RH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the embedding of one word\n",
        "word = \"queen\"\n",
        "glove_word_embedding[word]"
      ],
      "metadata": {
        "id": "e17bqoey4c86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the most similar words found in the training data\n",
        "glove_word_embedding.most_similar(word, topn=5)"
      ],
      "metadata": {
        "id": "eqoZd3DT4jaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the corpus, i.e. the dict of the words/index pairs used during the training\n",
        "vocab = glove_word_embedding.key_to_index\n",
        "np.random.choice(list(vocab.keys()), 10)"
      ],
      "metadata": {
        "id": "teQmk5s-4zoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6_di9dmpGZ_"
      },
      "source": [
        "## Get the embeddings from pre-trained models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDDtc1DxpGaA"
      },
      "source": [
        "### Example 1: glove-twitter-25 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgQh1RbmpGaA"
      },
      "outputs": [],
      "source": [
        "# Analogies, i.e. operations on the words and similarities\n",
        "# For instance, what is the most similar words of an operation like\n",
        "# king - man + woman ~ ?\n",
        "\n",
        "print(f\"Example 1: king - man + woman ~ ?\")\n",
        "analogy_w2v(word_embedding=glove_word_embedding, positive=[\"king\", \"woman\"], negative=[\"man\"], topn=5)\n",
        "\n",
        "print(f\"\\n\\nExample 1: doctor - man + woman ~ ?\")\n",
        "analogy_w2v(word_embedding=glove_word_embedding, positive=[\"doctor\", \"woman\"], negative=[\"man\"])\n",
        "\n",
        "print(f\"\\n\\nExample 2: doctor - father + mother ~ ?\")\n",
        "analogy_w2v(word_embedding=glove_word_embedding, positive=[\"doctor\", \"mother\"], negative=[\"father\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z8rSaaqpGaB"
      },
      "source": [
        "### Example 2: word2vec-google-news-300 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_FJYGmfpGaB"
      },
      "outputs": [],
      "source": [
        "print(f\"Example 1: man - woman ~ king - ?\")\n",
        "analogy_w2v(word_embedding=news_word_embedding, positive=[\"king\", \"woman\"], negative=[\"man\"], topn=5)\n",
        "\n",
        "print(f\"\\n\\nExample 1: man - woman ~ doctor - ?\")\n",
        "analogy_w2v(word_embedding=news_word_embedding, positive=[\"doctor\", \"woman\"], negative=[\"man\"])\n",
        "\n",
        "print(f\"\\n\\nExample 2: father - mother ~ doctor - ?\")\n",
        "analogy_w2v(word_embedding=news_word_embedding, positive=[\"doctor\", \"mother\"], negative=[\"father\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CURPpQVpGaF"
      },
      "source": [
        "## What about Transformers models ?\n",
        "\n",
        "Let's do the same operations for Transformers models (BERT and GPT2). Unfortunately, these models are not in gensim package so we use the package [transformers from HuggingFace](https://https://huggingface.co/docs/transformers/index).\n",
        "\n",
        "As the corpus is not embed in the pre-trained models, we choose to compute the analogies on some Gender Specific words as in Bolukbasi et al 2016.\n",
        "\n",
        "Then we compute the embeddings using transformers package and compare each word to a target_word with the cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the gender specific list (see Bolukbasi et al 2016)\n",
        "corpus = load_json(\"https://raw.githubusercontent.com/tolga-b/debiaswe/master/data/gender_specific_seed.json\")"
      ],
      "metadata": {
        "id": "nRIiL8VOB0N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBsDElYtpGaG"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True).eval()\n",
        "\n",
        "analogies = analogy(model, tokenizer, [\"doctor\", \"mother\"], [\"father\"], corpus)\n",
        "for similar in analogies:\n",
        "    print(similar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMCR8B7LpGaG"
      },
      "source": [
        "### GPT2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiKjQKW3pGaG"
      },
      "outputs": [],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2Model.from_pretrained(\"gpt2\")\n",
        "\n",
        "analogies = analogy(model, tokenizer, [\"doctor\", \"mother\"], [\"father\"], corpus)\n",
        "for similar in analogies:\n",
        "    print(similar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWZi2P_2pGaI"
      },
      "source": [
        "# Identifying genre subspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e8MfMQEpGaI"
      },
      "outputs": [],
      "source": [
        "def get_differences(word_embedding, text_1, text_2):\n",
        "    \"\"\"\n",
        "    Prepare the corpus for the PCA, see Bolukbasi et al 2016\n",
        "    \"\"\"\n",
        "    center = (word_embedding[text_1] + word_embedding[text_2]) / 2\n",
        "    return word_embedding[text_1] - center, word_embedding[text_2] - center"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt5NQOt3pGaI"
      },
      "outputs": [],
      "source": [
        "pairs = [[\"woman\", \"man\"], [\"girl\", \"boy\"], [\"she\", \"he\"], [\"mother\", \"father\"], [\"daughter\", \"son\"], [\"gal\", \"guy\"], [\"female\", \"male\"], [\"her\", \"his\"], [\"herself\", \"himself\"], [\"Mary\", \"John\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RBXVSFCpGaJ"
      },
      "outputs": [],
      "source": [
        "averages = []\n",
        "for text_1, text_2 in pairs:\n",
        "    diff_1, diff_2 = get_differences(news_word_embedding, text_1, text_2)\n",
        "    averages.append(diff_1)\n",
        "    averages.append(diff_2)\n",
        "averages = np.array(averages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqUBAbXfpGaJ"
      },
      "outputs": [],
      "source": [
        "scaled_inputs = StandardScaler(with_std=False).fit_transform(averages)\n",
        "\n",
        "pca = PCA(n_components=10).fit(scaled_inputs)\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "plt.plot(cumulative_explained_variance_ratio, \"o-\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1xSv-kNpGaJ"
      },
      "source": [
        "### Words visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGKEGq9KpGaJ"
      },
      "outputs": [],
      "source": [
        "from_pairs = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY8xh_POpGaK"
      },
      "outputs": [],
      "source": [
        "vocab = news_word_embedding.key_to_index\n",
        "\n",
        "# Some chosen words\n",
        "sample_words = [\"king\", \"husband\", \"treats\", \"heavy\", \"commit\", \"game\", \"seconds\", \"arrival\", \"tactical\", \"crafts\", \"identity\", \"trimester\", \"tanning\", \"user\", \"parts\", \"caused\", \"hoped\", \"modeling\", \"beautiful\", \"cake\", \"looks\", \"builder\", \"sewing\", \"dress\", \"letters\", \"nuclear\", \"hay\", \"quit\", \"brillient\", \"genius\", \"divorce\", \"cocky\", \"yard\", \"journeyman\", \"dancers\", \"thighs\", \"lust\", \"seeking\", \"ties\", \"guru\", \"salon\", \"buddy\", \"sassy\", \"frost\", \"bride\", \"groom\", \"governer\", \"sharply\", \"homemaker\", \"dancer\", \"roses\", \"pal\", \"daughter\", \"brass\", \"buddies\", \"burly\", \"feminist\", \"babe\", \"folks\", \"friend\", \"priest\", \"mate\", \"boyfriend\", \"boyfriends\", \"beard\", \"witch\", \"witches\", \"dads\", \"boys\", \"cousin\", \"chap\", \"boyhood\", \"actresses\", \"gals\", \"fiance\", \"wives\", \"son\", \"lad\", \"queen\", \"niece\", \"girlfriends\", \"guys\", \"girlfriend\", \"nephew\", \"grandmother\", \"wife\", \"ladies\", \"fiancee\"]\n",
        "sample_words = [word for word in sample_words if word in vocab]\n",
        "\n",
        "indexes = [vocab[word] for word in sample_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5dU8By2pGaK"
      },
      "outputs": [],
      "source": [
        "vectors = news_word_embedding.vectors[indexes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XetKGuvypGaK"
      },
      "outputs": [],
      "source": [
        "proj = pca.transform(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILjhwfxRpGaL"
      },
      "outputs": [],
      "source": [
        "padding = .5\n",
        "min_x = np.min(proj[:, 0]) - padding\n",
        "max_x = np.max(proj[:, 0]) + padding\n",
        "min_y = np.min(proj[:, 1]) - padding\n",
        "max_y = np.max(proj[:, 1]) + padding\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot([min_x, max_x], [0, 0], \"b-\", alpha=.35)\n",
        "ax.plot([0, 0], [min_y, max_y], \"b-\", alpha=.35)\n",
        "\n",
        "for idx, word in enumerate(sample_words):\n",
        "    ax.text(x=proj[idx, 0], y=proj[idx, 1], s=word)\n",
        "ax.set_xlim(min_x, max_x)\n",
        "ax.set_ylim(min_y, max_y)\n",
        "\n",
        "ax.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwb46vf_pGZ5"
      },
      "source": [
        "## Train Word2Vec using gensim package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKGh3IUNpGZ5"
      },
      "outputs": [],
      "source": [
        "# Prints the datasets available in gensim\n",
        "print(json.dumps(api.info().get(\"corpora\").get(\"text8\"), indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OX6z1EFpGZ6"
      },
      "outputs": [],
      "source": [
        "# Load a corpus\n",
        "corpus = api.load('text8')\n",
        "\n",
        "# Train Word2Vec\n",
        "model = Word2Vec(corpus, vector_size=100)\n",
        "print(f\"Finished after {model.epochs} epochs\")\n",
        "\n",
        "# Get the embedding object\n",
        "word_embedding = model.wv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqgop3arpGZ7"
      },
      "outputs": [],
      "source": [
        "word_embedding.most_similar(\"car\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eNybAIkpGZ8"
      },
      "outputs": [],
      "source": [
        "word_embedding.most_similar(\"nurse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeYVdeVPpGZ8"
      },
      "outputs": [],
      "source": [
        "word_embedding.most_similar(\"engineer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D540Su3GpGZ9"
      },
      "outputs": [],
      "source": [
        "word_embedding.most_similar(\"surgeon\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9aapBdXpGZ-"
      },
      "outputs": [],
      "source": [
        "# Get the embedding vectors\n",
        "vectors = word_embedding.vectors\n",
        "print(\"Embedding vectors dimensions:\", word_embedding.vectors.shape)\n",
        "\n",
        "# Get the vocab\n",
        "vocab_dict = word_embedding.key_to_index\n",
        "print(\"Vocabulary sample:\")\n",
        "print(np.random.choice(list(vocab_dict.keys()), 10))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}